"""
ç®€åŒ–çš„å·¥ä½œæµ - ä¸ä½¿ç”¨LangGraph
ç›´æ¥ç¼–æ’Pro/Con/Judgeä¸‰æ–¹äº¤äº’
"""

import uuid
from datetime import datetime
from urllib.parse import urlparse

import config
from agents.con_agent import ConAgent
from agents.judge_agent import JudgeAgent
from agents.pro_agent import ProAgent
from core.argumentation_graph import ArgumentationGraph
from core.evidence_pool import EvidencePool
from llm.qwen_client import QwenClient
from tools.attack_detector import AttackDetector
from tools.jina_search import JinaSearch
from utils.models import Evidence
from utils.models import Verdict


def assess_evidence_credibility(url: str, title: str) -> str:
    """
    è¯„ä¼°è¯æ®å¯ä¿¡åº¦

    è§„åˆ™:
    - æ”¿åºœ/å­¦æœ¯æœºæ„/çŸ¥ååª’ä½“ â†’ High
    - ä¸€èˆ¬ç½‘ç«™ â†’ Medium
    - å…¶ä»– â†’ Low
    """
    domain = urlparse(url).netloc.lower()

    # Highå¯ä¿¡åº¦åŸŸå
    high_cred_domains = ['gov', 'edu', 'who.int', 'wikipedia.org', 'nature.com', 'science.org', 'reuters.com',
        'bbc.com', 'cnn.com', 'nytimes.com', 'un.org']

    # Mediumå¯ä¿¡åº¦åŸŸå
    medium_cred_domains = ['com', 'org', 'net']

    for keyword in high_cred_domains:
        if keyword in domain:
            return "High"

    for keyword in medium_cred_domains:
        if keyword in domain:
            return "Medium"

    return "Low"


def assess_evidence_quality(content: str, credibility: str) -> float:
    """
    è¯„ä¼°è¯æ®è´¨é‡åˆ†æ•°

    è€ƒè™‘å› ç´ :
    - å¯ä¿¡åº¦
    - å†…å®¹é•¿åº¦
    """
    cred_score = {"High": 1.0, "Medium": 0.6, "Low": 0.3}.get(credibility, 0.5)
    length_score = min(1.0, len(content) / 500)

    return cred_score * 0.7 + length_score * 0.3


def run_debate_workflow(claim: str, max_rounds: int = 3) -> dict:
    """
    è¿è¡Œè¾©è®ºå·¥ä½œæµ

    æµç¨‹:
    1. åˆå§‹åŒ–LLMå’Œæœç´¢å·¥å…·
    2. å¤šè½®è¾©è®º:
       - Proå’ŒConç”ŸæˆæŸ¥è¯¢
       - å¹¶è¡Œæœç´¢
       - åˆ›å»ºè¯æ®èŠ‚ç‚¹
       - æ£€æµ‹æ”»å‡»å…³ç³»
    3. Judgeåšå‡ºåˆ¤å†³
    """
    print(f"\n{'=' * 80}")
    print(f"å¼€å§‹äº‹å®æ ¸æŸ¥: {claim}")
    print(f"{'=' * 80}\n")

    # åˆå§‹åŒ–
    llm = QwenClient(config.DASHSCOPE_API_KEY)
    jina = JinaSearch(config.JINA_API_KEY)
    evidence_pool = EvidencePool()
    arg_graph = ArgumentationGraph(claim)

    pro_agent = ProAgent(claim, llm)
    con_agent = ConAgent(claim, llm)
    attack_detector = AttackDetector(llm)

    # å¤šè½®è¾©è®º
    for round_num in range(1, max_rounds + 1):
        print(f"\n{'=' * 70}")
        print(f"ç¬¬ {round_num}/{max_rounds} è½®")
        print(f"{'=' * 70}")

        # 1. Proå’ŒConç”ŸæˆæŸ¥è¯¢
        print("\n[æŸ¥è¯¢ç”Ÿæˆ]")
        pro_queries = pro_agent.generate_search_queries(round_num, arg_graph, evidence_pool)
        con_queries = con_agent.generate_search_queries(round_num, arg_graph, evidence_pool)
        #
        # print(f"ProæŸ¥è¯¢ ({len(pro_queries)}ä¸ª): {pro_queries}")
        # print(f"ConæŸ¥è¯¢ ({len(con_queries)}ä¸ª): {con_queries}")

        # 2. æœç´¢å¹¶åˆ›å»ºè¯æ®
        print("\n[è¯æ®æœç´¢]")
        all_queries = [(q, "pro", round_num) for q in pro_queries] + [(q, "con", round_num) for q in con_queries]

        for query, agent, r_num in all_queries:
            try:
                print(f"æœç´¢: [{agent.upper()}] {query}")
                results = jina.search(query, top_k=2)  # æ¯ä¸ªæŸ¥è¯¢æœ€å¤š2ä¸ªç»“æœ

                for result in results:
                    # åˆ›å»ºEvidenceå¯¹è±¡
                    evidence_id = f"{agent}_{r_num}_{uuid.uuid4().hex[:8]}"
                    credibility = assess_evidence_credibility(result.get('url', ''), result.get('title', ''))
                    content = result.get('content', result.get('description', ''))

                    if len(content) < 50:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                        continue

                    quality_score = assess_evidence_quality(content, credibility)

                    evidence = Evidence(id=evidence_id, content=content, url=result.get('url', ''),
                        title=result.get('title', ''), source=urlparse(result.get('url', '')).netloc or 'æœªçŸ¥',
                        credibility=credibility, retrieved_by=agent, round_num=r_num, search_query=query,
                        timestamp=datetime.now(), quality_score=quality_score)

                    # æ·»åŠ åˆ°è¯æ®æ± å’Œè®ºè¾©å›¾
                    evidence_pool.add_evidence(evidence)
                    arg_graph.add_evidence_node(evidence)

                    print(f"  âœ“ æ·»åŠ è¯æ®: {evidence_id} (å¯ä¿¡åº¦:{credibility}, è´¨é‡:{quality_score:.2f})")

            except Exception as e:
                print(f"  âš  æœç´¢å¤±è´¥: {e}")

        # 3. æ£€æµ‹æ”»å‡»å…³ç³»
        print("\n[æ”»å‡»æ£€æµ‹]")
        new_attacks = attack_detector.detect_attacks_for_round(arg_graph, round_num)
        arg_graph.add_attacks(new_attacks)

        # æ˜¾ç¤ºæœ¬è½®ç»Ÿè®¡
        stats = evidence_pool.get_statistics()
        print(f"\n[æœ¬è½®ç»Ÿè®¡] Pro:{stats['pro']}ä¸ª, Con:{stats['con']}ä¸ª, æ€»è®¡:{stats['total']}ä¸ªè¯æ®")

    # # 4. Judgeåˆ¤å†³
    # print(f"\n{'='*80}")
    # print("è¾©è®ºç»“æŸ, Judgeå¼€å§‹åˆ¤å†³")
    # print(f"{'='*80}")
    #
    # judge_agent = JudgeAgent(llm)
    # verdict = judge_agent.make_verdict(claim, arg_graph, evidence_pool)

    # 4. è¾©è®ºæ€»ç»“

    print(f"\n{'=' * 80}")

    print("è¾©è®ºæ€»ç»“")

    print(f"{'=' * 80}")

    _print_debate_summary(claim, evidence_pool, arg_graph)

    # 5. Judgeåˆ¤å†³

    print(f"\n{'=' * 80}")

    print("Judge å¼€å§‹åˆ¤å†³")

    print(f"{'=' * 80}")

    judge_agent = JudgeAgent(llm)

    verdict = judge_agent.make_verdict(claim, arg_graph, evidence_pool)

    # 6. æ‰“å°æœ€ç»ˆæŠ¥å‘Š

    _print_final_report(claim, evidence_pool, arg_graph, verdict)

    # 7. è¿”å›ç»“æœ
    return {"claim": claim, "verdict": verdict.model_dump(), "evidence_pool_stats": evidence_pool.get_statistics(),
        "arg_graph_data": arg_graph.to_dict()}


# if __name__ == "__main__":
#     # æµ‹è¯•
#     test_claim = "æ¬§ç›Ÿè®¡åˆ’åœ¨2030å¹´å…¨é¢ç¦æ­¢é”€å”®ç‡ƒæ²¹è½¦ã€‚"
#     result = run_debate_workflow(test_claim, max_rounds=2)
#
#     print(f"\n\n{'='*80}")
#     print("æœ€ç»ˆåˆ¤å†³")
#     print(f"{'='*80}")
#     print(f"Claim: {result['claim']}")
#     print(f"Decision: {result['verdict']['decision']}")
#     print(f"Confidence: {result['verdict']['confidence']:.2f}")
#     print(f"Reasoning: {result['verdict']['reasoning']}")
def _print_debate_summary(claim: str, evidence_pool: EvidencePool, arg_graph: ArgumentationGraph):
    """æ‰“å°è¾©è®ºæ€»ç»“"""

    print(f"\nClaim: {claim}\n")

    # 1. æ‰€æœ‰è¯æ®åˆ—è¡¨

    print("ğŸ“‹ æ‰€æœ‰è¯æ® (æŒ‰è½®æ¬¡)")

    print("-" * 80)

    all_evidences = sorted(evidence_pool.get_all(), key=lambda e: (e.round_num, e.retrieved_by, e.id))

    for round_num in range(1, max([e.round_num for e in all_evidences]) + 1):

        # round_evidences = [e for e in all_evidences if e.round_num == round_num]
        #
        # if round_evidences:
        #
        #     print(f"\nç¬¬{round_num}è½®:")
        #
        #     for ev in round_evidences:
        #         icon = "âœ“" if ev.retrieved_by == "pro" else "âœ—"
        #
        #         print(
        #             f"  {icon} [{ev.id}] ({ev.retrieved_by.upper()}) ä¼˜å…ˆçº§:{ev.get_priority():.2f} å¯ä¿¡åº¦:{ev.credibility}")
        #
        #         print(f"      æ¥æº: {ev.source}")
        #
        #         print(f"      å†…å®¹: {ev.content[:120]}...")
        #
        #         print()
        round_evidences = [e for e in all_evidences if e.round_num == round_num]

        if round_evidences:

            print(f"\nç¬¬{round_num}è½®:")

            for ev in round_evidences:
                icon = "âœ“" if ev.retrieved_by == "pro" else "âœ—"

                print(
                    f"  {icon} [{ev.id}] ({ev.retrieved_by.upper()}) ä¼˜å…ˆçº§:{ev.get_priority():.2f} å¯ä¿¡åº¦:{ev.credibility}")

                print(f"      æ¥æº: {ev.source}")

                print(f"      å†…å®¹: {ev.content[:120]}...")

                print()

    # 2. æ”»å‡»å…³ç³»

    print("\nâš”ï¸  æ”»å‡»å…³ç³»")

    print("-" * 80)

    if arg_graph.attack_edges:

        for i, edge in enumerate(arg_graph.attack_edges, 1):
            attacker = arg_graph.get_node_by_id(edge.from_evidence_id)

            target = arg_graph.get_node_by_id(edge.to_evidence_id)

            print(f"{i}. [{edge.from_evidence_id}] ({attacker.retrieved_by.upper()}, P={attacker.get_priority():.2f})")

            print(f"   â†“ æ”»å‡» (å¼ºåº¦:{edge.strength:.2f})")

            print(f"   [{edge.to_evidence_id}] ({target.retrieved_by.upper()}, P={target.get_priority():.2f})")

            print(f"   ç†ç”±: {edge.rationale[:100]}...")

            print()

    else:

        print("æ— æ”»å‡»å…³ç³»")

    # 3. Grounded Extension (å°†åœ¨Judgeä¸­è®¡ç®—)

    print("\nğŸ¯ å³å°†è®¡ç®— Grounded Extension (å¯æ¥å—çš„è¯æ®é›†åˆ)...")


def _print_final_report(

        claim: str,
        evidence_pool: EvidencePool,
        arg_graph: ArgumentationGraph,
        verdict: Verdict

):
    """æ‰“å°æœ€ç»ˆæŠ¥å‘Š"""

    print(f"\n\n{'=' * 80}")
    print("ğŸ“Š æœ€ç»ˆæŠ¥å‘Š")
    print(f"{'=' * 80}\n")
    print(f"Claim: {claim}\n")

    # 1. è¢«æ¥å—çš„è¯æ®

    print("âœ… è¢«æ¥å—çš„è¯æ® (Grounded Extension)")
    print("-" * 80)
    accepted_ids = set(verdict.accepted_evidence_ids)

    if accepted_ids:
        for eid in accepted_ids:
            ev = arg_graph.get_node_by_id(eid)
            if ev:
                icon = "âœ“" if ev.retrieved_by == "pro" else "âœ—"
                print(f"{icon} [{ev.id}] ({ev.retrieved_by.upper()}) ä¼˜å…ˆçº§:{ev.get_priority():.2f}")
                print(f"    {ev.source}: {ev.content[:100]}...")
                print()

    else:
        print("æ— è¢«æ¥å—çš„è¯æ®")

    # 2. è¢«å‡»è´¥çš„è¯æ®

    print("\nâŒ è¢«å‡»è´¥çš„è¯æ®")
    print("-" * 80)
    all_ids = set(arg_graph.evidence_nodes.keys())
    defeated_ids = all_ids - accepted_ids
    if defeated_ids:

        for eid in defeated_ids:
            ev = arg_graph.get_node_by_id(eid)
            if ev:
                attackers = [arg_graph.get_node_by_id(aid) for aid in arg_graph.get_attackers(eid)]
                icon = "âœ“" if ev.retrieved_by == "pro" else "âœ—"
                print(f"{icon} [{ev.id}] ({ev.retrieved_by.upper()}) ä¼˜å…ˆçº§:{ev.get_priority():.2f}")
                if attackers:
                    print(f"    è¢«å‡»è´¥åŸå› : è¢« {[a.id for a in attackers]} æ”»å‡»")
                print()

    else:
        print("æ— è¢«å‡»è´¥çš„è¯æ®")

    # 3. åˆ¤å†³ç»“æœ

    print(f"\n{'=' * 80}")
    print("æœ€ç»ˆåˆ¤å†³")
    print(f"{'=' * 80}\n")
    decision_emoji = {"Supported": "âœ“", "Refuted": "âœ—", "NEI": "â“"}
    print(f"åˆ¤å†³: {decision_emoji.get(verdict.decision, '')} {verdict.decision}")
    print(f"ç½®ä¿¡åº¦: {verdict.confidence:.2%}")
    print(f"\næ¨ç†è¿‡ç¨‹:")
    print("-" * 80)
    print(verdict.reasoning)
    # 4. å…³é”®è¯æ®

    if verdict.key_evidence_ids:
        print(f"\nå…³é”®è¯æ®:")
        print("-" * 80)
        for eid in verdict.key_evidence_ids[:3]:
            ev = arg_graph.get_node_by_id(eid)
            if ev:
                print(f"â€¢ [{ev.id}] {ev.source}")
                print(f"  {ev.content[:150]}...")
                print()

    # 5. ç»Ÿè®¡ä¿¡æ¯

    print(f"\nç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 80)
    print(f"æ€»è¯æ®æ•°: {verdict.total_evidences}")
    print(f"è¢«æ¥å—: {verdict.accepted_evidences}")
    print(f"è¢«å‡»è´¥: {verdict.total_evidences - verdict.accepted_evidences}")
    print(f"æ”¯æŒå¼ºåº¦: {verdict.pro_strength:.2f}")
    print(f"åå¯¹å¼ºåº¦: {verdict.con_strength:.2f}")


if __name__ == "__main__":
    # æµ‹è¯•

    test_claim = "æ¬§ç›Ÿè®¡åˆ’åœ¨2030å¹´å…¨é¢ç¦æ­¢é”€å”®ç‡ƒæ²¹è½¦ã€‚"

    result = run_debate_workflow(test_claim, max_rounds=2)
