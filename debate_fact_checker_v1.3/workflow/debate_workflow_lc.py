"""
è¾©è®ºå·¥ä½œæµ - LangChain Lite ç‰ˆæœ¬

å®Œå…¨ä¿ç•™åŸå§‹ workflowï¼Œåªç”¨ LangChain Chain æ›¿ä»£ LLM è°ƒç”¨éƒ¨åˆ†
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

import uuid
from datetime import datetime
from urllib.parse import urlparse

import config
from core.argumentation_graph import ArgumentationGraph
from core.evidence_pool import EvidencePool
from llm.qwen_client import QwenClient
from tools.attack_detector import AttackDetector
from tools.jina_search import JinaSearch
from utils.models import Evidence, Verdict

# å¯¼å…¥ LangChain Chains
from chains import ProQueryChain, ConQueryChain, JudgeChain
from utils.qwen_wrapper import QwenLLMWrapper


def assess_evidence_credibility(url: str, title: str) -> str:
    """è¯„ä¼°è¯æ®å¯ä¿¡åº¦"""
    domain = urlparse(url).netloc.lower()
    high_cred_domains = ['gov', 'edu', 'who.int', 'wikipedia.org', 'nature.com',
                        'science.org', 'reuters.com', 'bbc.com', 'cnn.com',
                        'nytimes.com', 'un.org']

    for keyword in high_cred_domains:
        if keyword in domain:
            return "High"

    if any(ext in domain for ext in ['com', 'org', 'net']):
        return "Medium"

    return "Low"


def assess_evidence_quality(content: str, credibility: str) -> float:
    """è¯„ä¼°è¯æ®è´¨é‡åˆ†æ•°"""
    cred_score = {"High": 1.0, "Medium": 0.6, "Low": 0.3}.get(credibility, 0.5)
    length_score = min(1.0, len(content) / 500)
    return cred_score * 0.7 + length_score * 0.3


def run_debate_workflow_lc(claim: str, max_rounds: int = 3) -> dict:
    """
    è¿è¡Œè¾©è®ºå·¥ä½œæµ - LangChain Lite ç‰ˆæœ¬

    æµç¨‹ï¼ˆå®Œå…¨ä¿ç•™åŸå§‹ï¼‰:
    1. åˆå§‹åŒ–ç»„ä»¶
    2. å¤šè½®è¾©è®º:
       a. Pro & Con ç”ŸæˆæŸ¥è¯¢ï¼ˆä½¿ç”¨ Chainï¼‰
       b. æœç´¢å¹¶åˆ›å»º Evidence èŠ‚ç‚¹
       c. æ£€æµ‹æ”»å‡»å…³ç³»
       d. æ›´æ–°è®ºè¾©å›¾
    3. Judge åˆ¤å†³ï¼ˆä½¿ç”¨ Chainï¼‰
    """
    print(f"\n{'='*80}")
    print(f"LangChain Lite è¾©è®ºç³»ç»Ÿï¼ˆä¿ç•™åŸå§‹ workflowï¼‰")
    print(f"{'='*80}\n")
    print(f"Claim: {claim}\n")

    # 1. åˆå§‹åŒ–ç»„ä»¶
    llm_client = QwenClient(config.DASHSCOPE_API_KEY)

    jina = JinaSearch(config.JINA_API_KEY)
    evidence_pool = EvidencePool()
    arg_graph = ArgumentationGraph(claim)
    attack_detector = AttackDetector(llm_client)

    # åˆ›å»º LangChain Chainsï¼Œæ¯ä¸ªä½¿ç”¨ç‹¬ç«‹çš„ LLM wrapper å®ä¾‹ä»¥ä¾¿é…ç½®ä¸åŒçš„æœç´¢å‚æ•°
    # Pro Chain: enable_search=True, force_search=False (æ™ºèƒ½æœç´¢)
    pro_llm = QwenLLMWrapper(
        qwen_client=llm_client,
        enable_search=True,
        force_search=False,
        search_strategy="auto"
    )
    pro_chain = ProQueryChain(llm=pro_llm)

    # Con Chain: enable_search=True, force_search=False (æ™ºèƒ½æœç´¢)
    con_llm = QwenLLMWrapper(
        qwen_client=llm_client,
        enable_search=True,
        force_search=False,
        search_strategy="auto"
    )
    con_chain = ConQueryChain(llm=con_llm)

    # Judge Chain: å°†åœ¨ JudgeChain å†…éƒ¨ä¸ºä¸åŒæ–¹æ³•é…ç½®ä¸åŒå‚æ•°
    judge_llm = QwenLLMWrapper(
        qwen_client=llm_client,
        enable_search=False,  # é»˜è®¤å…³é—­ï¼Œåœ¨ make_verdict æ—¶å†å¼€å¯
        force_search=False
    )
    judge_chain = JudgeChain(llm=judge_llm)

    # è®°å½•æ‰€æœ‰æŸ¥è¯¢ï¼ˆé¿å…é‡å¤ï¼‰
    all_queries = []

    # 2. å¤šè½®è¾©è®º
    for round_num in range(1, max_rounds + 1):
        print(f"\n{'='*70}")
        print(f"ç¬¬ {round_num}/{max_rounds} è½®")
        print(f"{'='*70}\n")

        # 2.1 Pro & Con ç”ŸæˆæŸ¥è¯¢ï¼ˆä½¿ç”¨ LangChain Chainï¼‰
        print("[æŸ¥è¯¢ç”Ÿæˆ]")

        # Pro ç”ŸæˆæŸ¥è¯¢
        con_evidences = evidence_pool.get_by_agent("con")
        pro_queries = pro_chain.generate_queries(
            claim=claim,
            round_num=round_num,
            opponent_evidences=con_evidences,
            existing_queries=all_queries
        )

        # Con ç”ŸæˆæŸ¥è¯¢
        pro_evidences = evidence_pool.get_by_agent("pro")
        con_queries = con_chain.generate_queries(
            claim=claim,
            round_num=round_num,
            opponent_evidences=pro_evidences,
            existing_queries=all_queries
        )

        print(f"Pro æŸ¥è¯¢: {pro_queries}")
        print(f"Con æŸ¥è¯¢: {con_queries}")

        all_queries.extend(pro_queries)
        all_queries.extend(con_queries)

        # 2.2 æœç´¢å¹¶åˆ›å»º Evidence èŠ‚ç‚¹
        print("\n[è¯æ®æœç´¢]")
        all_search_queries = [(q, "pro", round_num) for q in pro_queries] + \
                            [(q, "con", round_num) for q in con_queries]

        for query, agent, r_num in all_search_queries:
            try:
                print(f"æœç´¢: [{agent.upper()}] {query}")
                results = jina.search(query, top_k=2)

                for result in results:
                    # åˆ›å»º Evidence å¯¹è±¡
                    evidence_id = f"{agent}_{r_num}_{uuid.uuid4().hex[:8]}"
                    credibility = assess_evidence_credibility(
                        result.get('url', ''),
                        result.get('title', '')
                    )
                    content = result.get('content', result.get('description', ''))

                    if len(content) < 50:
                        continue

                    quality_score = assess_evidence_quality(content, credibility)

                    evidence = Evidence(
                        id=evidence_id,
                        content=content,
                        url=result.get('url', ''),
                        title=result.get('title', ''),
                        source=urlparse(result.get('url', '')).netloc or 'æœªçŸ¥',
                        credibility=credibility,
                        retrieved_by=agent,
                        round_num=r_num,
                        search_query=query,
                        timestamp=datetime.now(),
                        quality_score=quality_score
                    )

                    # æ·»åŠ åˆ°è¯æ®æ± å’Œè®ºè¾©å›¾ï¼ˆæ¯ä¸ªè¯æ®æ˜¯ä¸€ä¸ªèŠ‚ç‚¹ï¼‰
                    evidence_pool.add_evidence(evidence)
                    arg_graph.add_evidence_node(evidence)

                    print(f"  âœ“ è¯æ®èŠ‚ç‚¹: {evidence_id} (å¯ä¿¡åº¦:{credibility}, è´¨é‡:{quality_score:.2f})")

            except Exception as e:
                print(f"  âš  æœç´¢å¤±è´¥: {e}")

        # 2.3 æ£€æµ‹æ”»å‡»å…³ç³»ï¼ˆè¯æ®èŠ‚ç‚¹ä¹‹é—´äº’ç›¸æ”»å‡»ï¼‰
        print("\n[æ”»å‡»æ£€æµ‹]")
        new_attacks = attack_detector.detect_attacks_for_round(arg_graph, round_num)
        arg_graph.add_attacks(new_attacks)
        print(f"âœ“ æ–°å¢ {len(new_attacks)} ä¸ªæ”»å‡»è¾¹")

        # æœ¬è½®ç»Ÿè®¡
        stats = evidence_pool.get_statistics()
        print(f"\n[æœ¬è½®ç»Ÿè®¡] Pro:{stats['pro']}ä¸ª, Con:{stats['con']}ä¸ª, æ€»è®¡:{stats['total']}ä¸ªè¯æ®èŠ‚ç‚¹")

    # 3. Judge åˆ¤å†³ï¼ˆä½¿ç”¨ LangChain Chainï¼‰
    print(f"\n{'='*80}")
    print("Judge åˆ¤å†³")
    print(f"{'='*80}\n")

    # è®¡ç®—è¢«æ¥å—çš„è¯æ®ï¼ˆGrounded Extensionï¼‰
    accepted_ids = arg_graph.compute_grounded_extension()
    accepted_evidences = [
        arg_graph.get_node_by_id(eid)
        for eid in accepted_ids
        if arg_graph.get_node_by_id(eid)
    ]

    print(f"è¢«æ¥å—çš„è¯æ®èŠ‚ç‚¹: {len(accepted_evidences)} ä¸ª")

    # ä½¿ç”¨ Judge Chain ç”Ÿæˆåˆ¤å†³
    verdict = judge_chain.make_verdict(
        claim=claim,
        accepted_evidences=accepted_evidences,
        all_evidences_count=len(arg_graph.evidence_nodes)
    )

    # 4. æ‰“å°æœ€ç»ˆæŠ¥å‘Š
    _print_final_report(claim, evidence_pool, arg_graph, verdict)

    # 5. æ„å»ºå®Œæ•´æ—¥å¿—
    complete_log = _build_complete_log(
        claim=claim,
        evidence_pool=evidence_pool,
        arg_graph=arg_graph,
        verdict=verdict,
        ground_truth=None  # å°†åœ¨ main ä¸­è®¾ç½®
    )

    # 6. è¿”å›ç»“æœ
    return {
        "claim": claim,
        "verdict": verdict.model_dump(),
        "evidence_pool_stats": evidence_pool.get_statistics(),
        "arg_graph_data": arg_graph.to_dict(),
        "complete_log": complete_log  # æ–°å¢ï¼šå®Œæ•´æ—¥å¿—
    }


def _print_final_report(
    claim: str,
    evidence_pool: EvidencePool,
    arg_graph: ArgumentationGraph,
    verdict: Verdict
):
    """æ‰“å°æœ€ç»ˆæŠ¥å‘Š"""
    print(f"\n\n{'='*80}")
    print("ğŸ“Š æœ€ç»ˆåˆ¤å†³")
    print(f"{'='*80}\n")
    print(f"Claim: {claim}\n")

    decision_emoji = {"Supported": "âœ“", "Refuted": "âœ—", "NEI": "â“"}
    print(f"åˆ¤å†³: {decision_emoji.get(verdict.decision, '')} {verdict.decision}")
    print(f"ç½®ä¿¡åº¦: {verdict.confidence:.2%}")
    print(f"\næ¨ç†è¿‡ç¨‹:")
    print("-" * 80)
    print(verdict.reasoning)

    if verdict.key_evidence_ids:
        print(f"\nå…³é”®è¯æ®èŠ‚ç‚¹:")
        print("-" * 80)
        for eid in verdict.key_evidence_ids[:3]:
            ev = arg_graph.get_node_by_id(eid)
            if ev:
                print(f"â€¢ [{ev.id}] {ev.source}")
                print(f"  {ev.content[:150]}...")
                print()

    print(f"\nç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 80)
    print(f"æ€»è¯æ®èŠ‚ç‚¹: {verdict.total_evidences}")
    print(f"è¢«æ¥å—: {verdict.accepted_evidences}")
    print(f"æ”¯æŒå¼ºåº¦: {verdict.pro_strength:.2f}")
    print(f"åå¯¹å¼ºåº¦: {verdict.con_strength:.2f}")


def _build_complete_log(
    claim: str,
    evidence_pool: EvidencePool,
    arg_graph: ArgumentationGraph,
    verdict: Verdict,
    ground_truth: str = None
) -> dict:
    """
    æ„å»ºå®Œæ•´çš„è¿è¡Œæ—¥å¿—

    Args:
        claim: Claim
        evidence_pool: è¯æ®æ± 
        arg_graph: è®ºè¾©å›¾
        verdict: åˆ¤å†³ç»“æœ
        ground_truth: æ•°æ®é›†ä¸­çš„çœŸå®æ ‡ç­¾

    Returns:
        å®Œæ•´æ—¥å¿—å­—å…¸
    """
    # 1. æ‰€æœ‰è¯æ®èŠ‚ç‚¹ï¼ˆæ ¼å¼åŒ–ï¼‰
    all_evidences = []
    for ev in evidence_pool.get_all():
        all_evidences.append({
            "id": ev.id,
            "content": ev.content,
            "url": ev.url,
            "source": ev.source,
            "credibility": ev.credibility,
            "quality_score": ev.quality_score,
            "priority": ev.get_priority(),
            "retrieved_by": ev.retrieved_by,
            "round_num": ev.round_num,
            "search_query": ev.search_query,
            "timestamp": ev.timestamp.isoformat() if hasattr(ev.timestamp, 'isoformat') else str(ev.timestamp)
        })

    # 2. æ”»å‡»å…³ç³»
    attack_edges = []
    for edge in arg_graph.attack_edges:
        attacker = arg_graph.get_node_by_id(edge.from_evidence_id)
        target = arg_graph.get_node_by_id(edge.to_evidence_id)

        attack_edges.append({
            "from_evidence_id": edge.from_evidence_id,
            "from_agent": attacker.retrieved_by if attacker else "unknown",
            "from_priority": attacker.get_priority() if attacker else 0,
            "to_evidence_id": edge.to_evidence_id,
            "to_agent": target.retrieved_by if target else "unknown",
            "to_priority": target.get_priority() if target else 0,
            "strength": edge.strength,
            "rationale": edge.rationale,
            "round_num": edge.round_num
        })

    # 3. è¢«æ¥å—çš„è¯æ®ï¼ˆGrounded Extensionï¼‰
    accepted_ids = arg_graph.compute_grounded_extension()
    accepted_evidences = []
    for eid in accepted_ids:
        ev = arg_graph.get_node_by_id(eid)
        if ev:
            accepted_evidences.append({
                "id": ev.id,
                "agent": ev.retrieved_by,
                "priority": ev.get_priority(),
                "source": ev.source,
                "content_preview": ev.content[:200] + "..."
            })

    # 4. è¢«å‡»è´¥çš„è¯æ®
    defeated_ids = set(arg_graph.evidence_nodes.keys()) - accepted_ids
    defeated_evidences = []
    for eid in defeated_ids:
        ev = arg_graph.get_node_by_id(eid)
        if ev:
            attackers = arg_graph.get_attackers(eid)
            defeated_evidences.append({
                "id": ev.id,
                "agent": ev.retrieved_by,
                "priority": ev.get_priority(),
                "defeated_by": list(attackers)
            })

    # 5. åˆ¤å†³ç»“æœ
    verdict_data = {
        "decision": verdict.decision,
        "confidence": verdict.confidence,
        "reasoning": verdict.reasoning,
        "key_evidence_ids": verdict.key_evidence_ids,
        "pro_strength": verdict.pro_strength,
        "con_strength": verdict.con_strength,
        "total_evidences": verdict.total_evidences,
        "accepted_evidences": verdict.accepted_evidences
    }

    # 6. ç»Ÿè®¡ä¿¡æ¯
    stats = evidence_pool.get_statistics()

    # 7. æ„å»ºå®Œæ•´æ—¥å¿—
    complete_log = {
        "claim": claim,
        "ground_truth": ground_truth,  # æ•°æ®é›†çœŸå®æ ‡ç­¾
        "timestamp": datetime.now().isoformat(),

        "statistics": {
            "total_evidences": stats['total'],
            "pro_evidences": stats['pro'],
            "con_evidences": stats['con'],
            "total_attacks": len(attack_edges),
            "accepted_evidences": len(accepted_evidences),
            "defeated_evidences": len(defeated_evidences)
        },

        "evidences": {
            "all_evidences": all_evidences,
            "accepted_evidences": accepted_evidences,
            "defeated_evidences": defeated_evidences
        },

        "argumentation": {
            "attack_edges": attack_edges,
            "grounded_extension": list(accepted_ids)
        },

        "verdict": verdict_data,

        "evaluation": {
            "predicted": verdict.decision,
            "ground_truth": ground_truth,
            "correct": verdict.decision == ground_truth if ground_truth else None
        }
    }

    return complete_log


if __name__ == "__main__":
    # æµ‹è¯•
    test_claim = "æ¬§ç›Ÿè®¡åˆ’åœ¨2030å¹´å…¨é¢ç¦æ­¢é”€å”®ç‡ƒæ²¹è½¦ã€‚"
    result = run_debate_workflow_lc(test_claim, max_rounds=2)

    print(f"\n\n{'='*80}")
    print("æµ‹è¯•å®Œæˆ")
    print(f"{'='*80}")
    print(f"åˆ¤å†³: {result['verdict']['decision']}")
    print(f"ç½®ä¿¡åº¦: {result['verdict']['confidence']:.2f}")